                                            第11章   目标检测
介绍基于卷积神经网络的目标检测算法，运行一个基于SSD(Single Shot Detection)算法的目标检测例子

11.1 目标检测算法简介
    11.1.1 滑窗法  Sliding Window

            1. 需要一个已经训练好的分类器
            2. 把图像按照一定间隔和不同大小分成一个个窗户
            3. 在这些窗户上执行分类器
                    如果突然得到较高分数，则认为是检测到物体
            4. 把每个窗口用分类器执行一遍，对得到的分数做一些后处理如
                    NMS(Non-Maximum Suppression)非极大值抑制
            5. 得到物体类别和对应区域

    11.1.2 PASCAL VOC 、mAP和IOU简介
            最常用的目标检测算法数据集、评估一个目标检测算法的最常见指标

            1. PASCAL VOC : Pattern Analysis Statistical Modelling and Computational Learning,Visual Object Classes
                   用于评估图像分类、检测、分隔和人体姿势动作的数据集
            2. 评价一个检测算法时，两个标准
                   是否正确预测框内物体类别  mAP( mean Average Precision)
                        平均精度均值
                        mAP是把每个类别的AP都单独拎出来，计算所有类别AP的平均值，代表着对检测到的目标平均精度的综合评价

                   预测的框和人工标注框的重合程度  IOU (Intersection Over Union)
                        衡量预测的物体框和真实框的重合程度
                        1. 重合度计算方法:
                               两个框重合的面积，除以两个框并集所占的面积，交并比
                        2. 评价一个算法时:
                                先设定一个IOU的阙值，只要算法找到的框的IOU大于这个阙值，就是一个有效的检测

     11.1.3 Selective Search 和 R-CNN简介

            1. Selective Search的思路:
                    1. 可能存在物体的区域都应该是有某种相似性或连续的区域
                    2. 超像素合并的思路:
                            1. 分割算法在图像上产生很多小区域
                                    这些区域是最基础的子区域，即超像素
                            2. 根据区域之间的相似性进行区域合并，成为大一点的区域
                            3. 整张图会合并成为一个区域
                            4. 这个过程，每个区域做一个外切的矩形，得到可能是物体的区域方框，即Region Proposal

    11.1.4   SPP 、ROI Pooling 和 Fast R-CNN简介

            1. SPP和ROI Pooling
                    一个思路：
                            对整张图片执行一次卷积神经网络的前向计算，最后一层的激活响应图时，通过某种方式把目标物体所在区域部分
                            的响应图拿出来作为特征还给分类器

                    1. SPP(Spatial Pyramid Pooling) 空间金字塔池化
                            1. 假设输入图片框经过Selective Search，经过卷积神经网络，最后一层输出n个通道的响应图时，原图像
                                上的两个框对应两个区域，这样的区域称为感兴趣区域Region Of Interest,ROI
                            2. 对每一个ROI
                                    SPP分层将制定区域划分为不同数目
                                    1.图中分为3个层次，最底层划分为4*4=16个子区域，
                                    2. 中间层是2*2=4个子区域
                                    3. 最顶层则直接整个区域进行池化
                                    4. 对于每个通道，每个ROI变成一个21维的向量，因为有n个通道，所以每个ROI生成一个21n维的向量
                                    5. SPP通过金字塔一样的结构来获得感兴趣区域不同尺度的信息，所以叫空间金字塔池化

                    2. Fast R-CNN简介
                            1. ROI提取特征后，把物体框的回归和分类这两个任务的loss融合一起训练，端到端的多任务训练
                            2. 把SPP换成ROI Pooling，
                            3. 主要是loss计算方法不同

    11.1.5  RPN 和 Faster R-CNN

            1. RPN ----- Region Proposal Networks
                代替Selective Search，把算法所有步骤都被包含到一个完整的框架中，实现端到端训练

                    1. 首先对基础网络最后一层卷积响应图，按照执行一次n*n卷积，输出指定通道的响应图
                    2. 然后对得到的响应图的每个像素分别进入两个全连接层:
                            一个计算该像素对应位置是否有物体的分数，输出是或否的分数，两个输出
                            一个计算物体框的二维坐标大小，4个输出
                    3. 对每一个n*n卷积输出的响应图像素，用中心在该像素位置，不同大小和不同长宽比的窗口作为anchor box
                    4. 回归物体框坐标和大小的网络是在anchor box基础上做offset
                    5. 所以假设有k个anchor box，则计算是否有物体分数的输出实际有2k个，计算物体框坐标和大小的输出实际有4k个

            2. Faster R--CNN
                    1. 基于RPN的物体分数和物体框得到可能的物体框后，训练时经过NMS和分数从大到小排序筛选出有效的物体框
                        从中随机选取作为一个batch
                    2. 通过ROI Pooling进行分类同时，进一步对物体框的位置及大小进行回归，
                    3. ROI Pooling之后这两个任务对应两个loss，再和RPN的两个loss放一起实现端到端的训练

     11.1.6 YOLO和SSD简介

            1. YOLO --- You only look once
                 思路 : 把一张图片划分为一个S*S的格子，以每个格子所在位置和对应内容为基础,来预测:
                    1. 物体框 ，包含物体框中心相对格子中心的坐标(x,y)和物体框的宽w和高h，每个格子预测B个物体框
                    2. 每个物体框是否有物体的置信度，其中当前这个格子中如果包含物体，则置信度的分数为当前预测的物体框和标准
                        物体框的IOU，否则置信度分数为0
                    3. 每个格子预测一共C个类别的概率分数，并且这个分数和物体框是不相关的，只是基于这个格子
                    4. 综上，每个格子需要输出的信息维度是B*(4+1)+C=B*5+C

             2. SSD --- Single Shot multibox Detector
                    1. SSD会在卷积神经网络的最后阶段，得到S*S的响应图
                    2. 和R-CNN相近地方，SSD会基于每个格子的位置借鉴anchor box的思想生成默认物体框
                    3. SSD相对于YOLO，主要改进是从一个分辨率较大的响应图开始，逐渐得到分辨率更低的响应图，
                        每个分辨率下的响应图作为产生物体类别分数和物体框的格子
11.2 基于PASCAL VOC数据集训练SSD模型

     11.2.1 MXNet的SSD实现

           具体实现在mxnet根目录中的example\ssd目录下
                  1. config----训练相关设置，如随机镜像和检测及每个epoch的随机设置
                  2. data----默认存放数据或者数据软链接
                  3. dataset-----数据迭代的实现，默认是支持PASCAL VOC数据格式
                  4. 训练物体类别定义是在dataset/pascal_voc.py实现，
                      如果需要训练自己的数据，要在这个文件夹中作出相应修改
                  5. detect-----包含执行目录检测的代码和接口
                  6. evaludate-----封装目标检测代码并评估模型指标的脚本
                  7. model-----存储模型结构和参数值
                  8. operator-----对MXNet默认不包含的底层操作的实现
                            如Faster R-CNN中的Region Proposal
                            SSD中默认物体框和标注框的匹配，正负样本的选取
                            NMS操作的实现代码
                  9. symbol-----网络结构的定义
                  10. tools-----常用基本操作如随机裁剪和随机补边
                  11. train-----训练网络的基本操作，由根目录下的train.py调用

     11.2.2 下载PASCAL VOC数据集

           1. VOCdevkit:
                  1. Annotations:
                        所有标注信息时xml格式，
                        <object>标注物体名称<name>
                        物体框坐标<bndbox>
                        JPEGImages文件夹下是和Annotations文件夹下的xml文件同名的jpg图片文件

     11.2.3 训练SSD模型

           1.
     11.2.4 测试和评估模型效果

           1.
     11.2.5 物体检测结果可视化

           1.




































